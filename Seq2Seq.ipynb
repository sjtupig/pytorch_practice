{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先创建数据集，每个句子都以EOS结束，以PAD填充.翻译时以EOS开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD, BOS, EOS = '<pad>', '<bos>', '<eos>'\n",
    "#设置每个句子最长为10\n",
    "max_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_seq(seq_tokens, word_tokens, seqs):\n",
    "    for i in seq_tokens:\n",
    "        if i not in word_tokens:\n",
    "            word_tokens[i] = max(word_tokens.values())+1\n",
    "    seq_tokens += [EOS]+[PAD]*(max_length-len(seq_tokens)-1)\n",
    "    seqs.append(seq_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_word_tokens = {\n",
    "    '<pad>':0,\n",
    "    '<bos>':1,\n",
    "    '<eos>':1\n",
    "}#存词-索引字典\n",
    "fr_word_tokens = {\n",
    "    '<pad>':0,\n",
    "    '<bos>':1,\n",
    "    '<eos>':2\n",
    "}\n",
    "en_seqs = []#输入数据的索引数据\n",
    "fr_seqs = []\n",
    "with open('data\\\\eng-fra.txt', 'r', encoding='utf8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        en_seq, fr_seq = line.strip().split('\\t')\n",
    "        en_tokens, fr_tokens = en_seq.strip().split(' '), fr_seq.strip().split(' ')\n",
    "        if max(len(en_tokens), len(fr_tokens)) > max_length-1:\n",
    "            continue\n",
    "        process_seq(en_tokens, en_word_tokens, en_seqs)\n",
    "        process_seq(fr_tokens, fr_word_tokens, fr_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(word_tokens, seqs):\n",
    "    data = [[word_tokens[j] for j in i] for i in seqs]\n",
    "    return torch.LongTensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data = getData(en_word_tokens, en_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_data = getData(fr_word_tokens, fr_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TensorDataset(en_data, fr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参数配置表\n",
    "batch_size = 1\n",
    "en_word_nums = len(en_word_tokens.keys())\n",
    "fr_word_nums = len(fr_word_tokens.keys())\n",
    "embedding_size = 128\n",
    "gru_hidden_size = 128\n",
    "attention_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataLoader(data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_en_words_tokens = {value:key for key, value in en_word_tokens.items()}\n",
    "re_fr_words_tokens = {value:key for key, value in fr_word_tokens.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  31, 3075,  247,  487,  420, 2123,  111, 2220,    1,    0]]), tensor([[   19,    49,  5270,    68, 12881,  1113,  4315,     2,     0,     0]])]\n",
      "I'm lucky to have you as a friend. <eos> <pad> -> Je suis chanceux de t'avoir pour ami. <eos> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    en_seq, fr_seq = i\n",
    "    print(i)\n",
    "    for j in range(batch_size):\n",
    "        print(' '.join([re_en_words_tokens[i] for i in en_seq.numpy()[j]]), '->', ' '.join([re_fr_words_tokens[i] for i in fr_seq.numpy()[j]]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layer = 1\n",
    "        self.emb = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_size,self.num_layer, batch_first=True)\n",
    "    \n",
    "    def forward(self, data_input, init_hidden):\n",
    "        self.data_embd = self.emb(data_input)\n",
    "        outputs, h = self.gru(self.data_embd, init_hidden)\n",
    "        return outputs, h\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.num_layer, self.batch_size,self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_size, attention_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, attention_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(attention_size,1)\n",
    "    \n",
    "    def forward(self,encode_states, decode_states):\n",
    "        decode_states = decode_states.squeeze(0).unsqueeze(1)\n",
    "        decode_states, encode_states = torch.broadcast_tensors(decode_states, encode_states)\n",
    "        en_de_states = torch.cat((encode_states, decode_states), dim=2)\n",
    "        l1 = self.linear1(en_de_states)\n",
    "        l2 = self.tanh(l1)\n",
    "        l3 = self.linear2(l2)\n",
    "        weights = nn.Softmax(dim=1)(l3)\n",
    "        contexts = torch.mul(weights,encode_states).sum(dim=1).unsqueeze_(0)\n",
    "        return contexts, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size, attention_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.num_layer = 1\n",
    "        self.emb = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim+hidden_size, hidden_size, self.num_layer, batch_first=True)\n",
    "        self.attention = Attention(2*gru_hidden_size, attention_size)\n",
    "        self.output = nn.Linear(self.hidden_size, self.num_embeddings)\n",
    "    \n",
    "    def forward(self, data_input, encode_states, decode_states):\n",
    "        self.data_embd = self.emb(data_input)\n",
    "        self.contexts, self.weights = self.attention(encode_states, decode_states)\n",
    "        self.contexts = self.contexts.squeeze(0).unsqueeze(1)\n",
    "        self.data = torch.cat((self.data_embd, self.contexts), dim = 2)\n",
    "        outputs, h = self.gru(self.data, decode_states)\n",
    "        y = self.output(outputs)\n",
    "        outputs = F.log_softmax(y, dim=2)\n",
    "        return outputs.squeeze(1), h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_loss(encoder, decoder, batch_size, input_tensor, target_tensor, lossf):\n",
    "    init_encode_hidden = encoder.init_hidden()\n",
    "    encode_states, en_h0 = encoder(input_tensor, init_encode_hidden)\n",
    "    dec_input = torch.LongTensor([fr_word_tokens[BOS]] * batch_size).view(batch_size,-1)\n",
    "    decode_states = en_h0\n",
    "    mask, num_not_pad_tokens = torch.ones(batch_size), 0\n",
    "    batchloss = torch.tensor(0.0)\n",
    "    for y in target_tensor.transpose(0,1):\n",
    "        outputs, decode_states = decoder(dec_input, encode_states, decode_states)\n",
    "        batchloss += (mask*lossf(outputs, y)).sum()\n",
    "        dec_input = y.view(batch_size,-1)\n",
    "        num_not_pad_tokens += mask.sum().item()\n",
    "        t = y != torch.LongTensor([fr_word_tokens[EOS]])\n",
    "        mask = mask * (t.float())\n",
    "        #print(batchloss, num_not_pad_tokens)\n",
    "    return batchloss/num_not_pad_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_data(en_data, fr_data, num):\n",
    "    idx = torch.randint(low=0, high=len(en_data), size = (num,))\n",
    "    return en_data[idx,:].view(-1,max_length), fr_data[idx,:].view(-1,max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(en_word_nums, embedding_size, gru_hidden_size, batch_size)\n",
    "decoder = Decoder(fr_word_nums, embedding_size, gru_hidden_size, attention_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "epo_bat = 50\n",
    "loss = []\n",
    "encode_optimizer = optim.SGD(encoder.parameters(), lr=0.01, momentum=0.9)\n",
    "decode_optimizer = optim.SGD(decoder.parameters(), lr=0.01, momentum=0.9)\n",
    "lossf = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 epoch_b 0 loss: tensor(10.4609, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 1 loss: tensor(10.4261, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 2 loss: tensor(10.3601, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 3 loss: tensor(10.2661, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 4 loss: tensor(10.1471, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 5 loss: tensor(10.0057, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 6 loss: tensor(9.8442, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 7 loss: tensor(9.6643, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 8 loss: tensor(9.4676, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 9 loss: tensor(9.2547, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 10 loss: tensor(9.0260, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 11 loss: tensor(8.7812, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 12 loss: tensor(8.5192, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 13 loss: tensor(8.2387, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 14 loss: tensor(7.9379, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 15 loss: tensor(7.6148, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 16 loss: tensor(7.2671, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 17 loss: tensor(6.8928, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 18 loss: tensor(6.4896, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 19 loss: tensor(6.0558, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 20 loss: tensor(5.5898, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 21 loss: tensor(5.0911, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 22 loss: tensor(4.5597, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 23 loss: tensor(3.9978, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 24 loss: tensor(3.4103, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 25 loss: tensor(2.8073, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 26 loss: tensor(2.2079, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 27 loss: tensor(1.6431, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 28 loss: tensor(1.1523, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 29 loss: tensor(0.7687, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 30 loss: tensor(0.4999, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 31 loss: tensor(0.3273, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 32 loss: tensor(0.2217, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 33 loss: tensor(0.1576, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 34 loss: tensor(0.1181, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 35 loss: tensor(0.0929, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 36 loss: tensor(0.0761, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 37 loss: tensor(0.0646, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 38 loss: tensor(0.0564, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 39 loss: tensor(0.0503, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 40 loss: tensor(0.0456, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 41 loss: tensor(0.0419, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 42 loss: tensor(0.0388, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 43 loss: tensor(0.0363, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 44 loss: tensor(0.0341, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 45 loss: tensor(0.0321, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 46 loss: tensor(0.0304, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 47 loss: tensor(0.0288, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 48 loss: tensor(0.0274, grad_fn=<DivBackward0>)\n",
      "epoch: 0 epoch_b 49 loss: tensor(0.0261, grad_fn=<DivBackward0>)\n",
      "epoch: 1 epoch_b 0 loss: tensor(12.1897, grad_fn=<DivBackward0>)\n",
      "epoch: 1 epoch_b 1 loss: tensor(11.7946, grad_fn=<DivBackward0>)\n",
      "epoch: 1 epoch_b 2 loss: tensor(11.0920, grad_fn=<DivBackward0>)\n",
      "epoch: 1 epoch_b 3 loss: tensor(10.2962, grad_fn=<DivBackward0>)\n",
      "epoch: 1 epoch_b 4 loss: tensor(9.5452, grad_fn=<DivBackward0>)\n",
      "epoch: 1 epoch_b 5 loss: tensor(8.8483, grad_fn=<DivBackward0>)\n",
      "epoch: 1 epoch_b 6 loss: tensor(8.1739, grad_fn=<DivBackward0>)\n",
      "epoch: 1 epoch_b 7 loss: tensor(7.4970, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-0ff8ff63957f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mbatchloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlossf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mbatchloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mencode_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mdecode_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dingyang\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\optim\\sgd.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     98\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'momentum_buffer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m                         \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    input_tensors, target_tensors = get_random_data(en_data, fr_data, epo_bat)\n",
    "    for j in range(epo_bat):\n",
    "        input_tensor, target_tensor = input_tensors[i,:].view(-1,max_length), target_tensors[i,:].view(-1,max_length)\n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "        batchloss = batch_loss(encoder, decoder, batch_size, input_tensor, target_tensor, lossf)\n",
    "        batchloss.backward()\n",
    "        encode_optimizer.step()\n",
    "        decode_optimizer.step()\n",
    "        loss.append(batchloss.item())\n",
    "        print('epoch:',i, 'epoch_b', j, 'loss:',batchloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)\n",
    "plt.ylabel('some numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = torch.randint(low=0, high=len(en_data), size = (50,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(encoder, decoder, input_tensor):\n",
    "    init_encode_hidden = torch.zeros(1,1,128)\n",
    "    encode_states, en_h0 = encoder(input_tensor, init_encode_hidden)\n",
    "    decode_states = en_h0\n",
    "    dec_input = torch.LongTensor([fr_word_tokens[BOS]] * 1).view(1,-1)\n",
    "    pred_tokens = []\n",
    "    for _ in range(max_length):\n",
    "        outputs, decode_states = decoder(dec_input, encode_states, decode_states)\n",
    "        pred = outputs.argmax(dim=1)\n",
    "        pred_token = re_fr_words_tokens[pred.item()]\n",
    "        if pred_token == EOS:\n",
    "            break\n",
    "        else:\n",
    "            dec_input = pred.view(-1,1)\n",
    "            pred_tokens.append(pred_token)\n",
    "    return ' '.join(pred_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 94317,  37035,  87330, 108005, 100095,  54012,  66127,  60659,  17929,\n",
       "         19612,   3364,  51565,   7827,  21761, 106184, 106226,  25508,  66734,\n",
       "         70958,  57745,  18636,  95461,  18577,  29399,  40445,   4547,  17796,\n",
       "         45849,   3599,  23927,   3315,  70496,  25553, 101639,  57824,  60602,\n",
       "         52346,  78851,  32392,  84310,  62354,   6985,  60297,  55212,  37511,\n",
       "         58030,  41783,     57,  10098,  34792])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************** testid: 0 **********************************\n",
      "I wonder why karaoke is so popular. <eos> <pad> <pad> -> Je me demande pourquoi le karaoké est aussi populaire. <eos>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 1 **********************************\n",
      "Do you play any sports? <eos> <pad> <pad> <pad> <pad> -> Pratiques-tu quelque sport ? <eos> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 2 **********************************\n",
      "I want to know why this happened. <eos> <pad> <pad> -> Je veux savoir pourquoi ceci s'est produit. <eos> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 3 **********************************\n",
      "They spent the afternoon around the pool. <eos> <pad> <pad> -> Elles ont passé l'après-midi autour de la piscine. <eos> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 4 **********************************\n",
      "She advised him to keep his promises. <eos> <pad> <pad> -> Elle lui a conseillé de tenir ses promesses. <eos> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 5 **********************************\n",
      "I still love this bicycle. <eos> <pad> <pad> <pad> <pad> -> J'adore toujours ce vélo. <eos> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 6 **********************************\n",
      "That's all I needed to hear. <eos> <pad> <pad> <pad> -> C'est tout ce dont j'avais besoin d'entendre. <eos> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 7 **********************************\n",
      "She has an agreeable voice. <eos> <pad> <pad> <pad> <pad> -> Elle a une agréable voix. <eos> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 8 **********************************\n",
      "What's your major? <eos> <pad> <pad> <pad> <pad> <pad> <pad> -> Quelle est ta spécialité ? <eos> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 9 **********************************\n",
      "I hate to complain. <eos> <pad> <pad> <pad> <pad> <pad> -> Je déteste me plaindre. <eos> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 10 **********************************\n",
      "It amazed me. <eos> <pad> <pad> <pad> <pad> <pad> <pad> -> Ça m'a épaté. <eos> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 11 **********************************\n",
      "Write at least 250 words. <eos> <pad> <pad> <pad> <pad> -> Écris au moins 250 mots. <eos> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 12 **********************************\n",
      "Try this sauce. <eos> <pad> <pad> <pad> <pad> <pad> <pad> -> Essaie cette sauce. <eos> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 13 **********************************\n",
      "We've just arrived. <eos> <pad> <pad> <pad> <pad> <pad> <pad> -> Nous venons d'arriver. <eos> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 14 **********************************\n",
      "Settle down for a while and concentrate. <eos> <pad> <pad> -> Pose-toi un instant. <eos> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 15 **********************************\n",
      "She is now staying at her uncle's house. <eos> <pad> -> Maintenant, elle est chez son oncle. <eos> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 16 **********************************\n",
      "They are our guests. <eos> <pad> <pad> <pad> <pad> <pad> -> Ils sont nos invités. <eos> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 17 **********************************\n",
      "Tom probably went to Boston. <eos> <pad> <pad> <pad> <pad> -> Tom a probablement été à Boston. <eos> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 18 **********************************\n",
      "That boy is speaking English. <eos> <pad> <pad> <pad> <pad> -> Ce garçon sait parler anglais. <eos> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 19 **********************************\n",
      "Could you read this for me? <eos> <pad> <pad> <pad> -> Pourriez-vous me lire cela ? <eos> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 20 **********************************\n",
      "Did anyone hear me? <eos> <pad> <pad> <pad> <pad> <pad> -> Quelqu'un m'a-t-il entendu ? <eos> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 21 **********************************\n",
      "Tom is a much better liar than you. <eos> <pad> -> Tom est un meilleur menteur que vous. <eos> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 22 **********************************\n",
      "Can I rent rackets? <eos> <pad> <pad> <pad> <pad> <pad> -> Puis-je louer des raquettes ? <eos> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 23 **********************************\n",
      "It's not fair to you. <eos> <pad> <pad> <pad> <pad> -> Ce n'est pas juste envers toi. <eos> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 24 **********************************\n",
      "Tom amazes me at times. <eos> <pad> <pad> <pad> <pad> -> Tom me surprend par moment. <eos> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 25 **********************************\n",
      "I had no clue. <eos> <pad> <pad> <pad> <pad> <pad> -> Je n'en avais aucune idée. <eos> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 26 **********************************\n",
      "We're not so sure. <eos> <pad> <pad> <pad> <pad> <pad> -> Nous n'en sommes pas si sûrs. <eos> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 27 **********************************\n",
      "We'd better go home now. <eos> <pad> <pad> <pad> <pad> -> Nous ferions mieux de rentrer chez nous, maintenant. <eos> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 28 **********************************\n",
      "That is mine. <eos> <pad> <pad> <pad> <pad> <pad> <pad> -> C'est le mien. <eos> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 29 **********************************\n",
      "I meant what I said. <eos> <pad> <pad> <pad> <pad> -> Je pensais ce que j'ai dit. <eos> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 30 **********************************\n",
      "I've done it. <eos> <pad> <pad> <pad> <pad> <pad> <pad> -> Je l'ai fait. <eos> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 31 **********************************\n",
      "My friend called me a coward. <eos> <pad> <pad> <pad> -> Mon ami m'a traité de lâche. <eos> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 32 **********************************\n",
      "They handcuffed Tom. <eos> <pad> <pad> <pad> <pad> <pad> <pad> -> Ils ont menotté Tom. <eos> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 33 **********************************\n",
      "I finally went to England this summer. <eos> <pad> <pad> -> Je suis finalement allé en Angleterre cet été. <eos> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 34 **********************************\n",
      "Didn't you hear me calling? <eos> <pad> <pad> <pad> <pad> -> Ne m'avez-vous pas entendu appeler ? <eos> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 35 **********************************\n",
      "She came close to drowning. <eos> <pad> <pad> <pad> <pad> -> Elle a failli se noyer. <eos> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************** testid: 36 **********************************\n",
      "Does anyone speak English? <eos> <pad> <pad> <pad> <pad> <pad> -> Quiconque parle-t-il anglais ? <eos> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 37 **********************************\n",
      "I really can't leave right now. <eos> <pad> <pad> <pad> -> Je ne peux vraiment pas partir immédiatement. <eos> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 38 **********************************\n",
      "He became a policeman. <eos> <pad> <pad> <pad> <pad> <pad> -> Il est devenu policier. <eos> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 39 **********************************\n",
      "She tends to be late for school. <eos> <pad> <pad> -> Elle a tendance à arriver en retard à l'école. <eos>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 40 **********************************\n",
      "Write in the date yourself. <eos> <pad> <pad> <pad> <pad> -> Écrivez-y vous-même la date. <eos> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 41 **********************************\n",
      "I'll pay later. <eos> <pad> <pad> <pad> <pad> <pad> <pad> -> Je payerai plus tard. <eos> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 42 **********************************\n",
      "Let's say no more about it. <eos> <pad> <pad> <pad> -> Ne disons rien de plus à ce sujet. <eos> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 43 **********************************\n",
      "Keep focused on your work. <eos> <pad> <pad> <pad> <pad> -> Restez concentrés sur votre travail ! <eos> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 44 **********************************\n",
      "He made a bad decision. <eos> <pad> <pad> <pad> <pad> -> Il prit une mauvaise décision. <eos> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 45 **********************************\n",
      "Don't lose sleep over that. <eos> <pad> <pad> <pad> <pad> -> N'en perds pas le sommeil. <eos> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 46 **********************************\n",
      "Are you referring to me? <eos> <pad> <pad> <pad> <pad> -> Vous faites allusion à moi ? <eos> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 47 **********************************\n",
      "We won. <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> -> Nous l'emportâmes. <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 48 **********************************\n",
      "No one got sick. <eos> <pad> <pad> <pad> <pad> <pad> -> Personne n'a été malade. <eos> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n",
      "********************************** testid: 49 **********************************\n",
      "She got brushed aside. <eos> <pad> <pad> <pad> <pad> <pad> -> Elle s'est fait écarter. <eos> <pad> <pad> <pad> <pad> <pad>\n",
      "Mon vélo a un pneu à plat.\n"
     ]
    }
   ],
   "source": [
    "testid = 0\n",
    "for idx in index:\n",
    "    input_tensor,target_tensor = en_data[idx,:].view(1,-1), fr_data[idx,:].view(1,-1)\n",
    "    print('**********************************','testid:',testid,'**********************************')\n",
    "    print(' '.join([re_en_words_tokens[i] for i in input_tensor.numpy()[0]]), '->', ' '.join([re_fr_words_tokens[i] for i in target_tensor.numpy()[0]]))\n",
    "    print(predict(encoder, decoder, input_tensor))\n",
    "    testid += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
